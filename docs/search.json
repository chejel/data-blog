[
  {
    "objectID": "posts/himalayan/index.html",
    "href": "posts/himalayan/index.html",
    "title": "Himalayan Expeditions",
    "section": "",
    "text": "See full chart below.\n\n\n\n\n\n\n\n\nWhat is #TidyTuesday?\n\n\n\n\n\nTidy Tuesday is a weekly project that provides a dataset for R users to explore and visualize. On September 22, 2020, it featured data from The Himalayan Database, which contains information on expeditions from 1905 through spring 2019 (the online database itself goes up to spring 2021) that scaled more than 465 major peaks in the Nepal Himalayas.\n\n\n\nAccording to the Himalayan Database:\n\nThe database is based on the expedition archives of Elizabeth Hawley, a longtime journalist based in Kathmandu, and it is supplemented by information gathered from books, alpine journals and correspondence with Himalayan climbers.\n(…)\nEach expedition record contains detailed information including dates, routes, camps, use of supplemental oxygen, successes, deaths and accidents.\nEach expedition record contains biographical information for all members listed on the permit as well as for hired members (e.g., Sherpas) for which there are significant events such as a summit success, death, accident or rescue.\n\nThis post shows the exploration process of two of the datasets, and uses the tidyverse set of R packages for data wrangling and visualization.\nStarting out with an overview of the records:\n\n\n\n\nglimpse(expeditions)\n\nRows: 10,364\nColumns: 16\n$ expedition_id      <chr> \"ANN260101\", \"ANN269301\", \"ANN273101\", \"ANN278301\",…\n$ peak_id            <chr> \"ANN2\", \"ANN2\", \"ANN2\", \"ANN2\", \"ANN2\", \"ANN2\", \"AN…\n$ peak_name          <chr> \"Annapurna II\", \"Annapurna II\", \"Annapurna II\", \"An…\n$ year               <dbl> 1960, 1969, 1973, 1978, 1979, 1980, 1980, 1981, 198…\n$ season             <chr> \"Spring\", \"Autumn\", \"Spring\", \"Autumn\", \"Autumn\", \"…\n$ basecamp_date      <date> 1960-03-15, 1969-09-25, 1973-03-16, 1978-09-08, NA…\n$ highpoint_date     <date> 1960-05-17, 1969-10-22, 1973-05-06, 1978-10-02, 19…\n$ termination_date   <date> NA, 1969-10-26, NA, 1978-10-05, 1979-10-20, 1980-0…\n$ termination_reason <chr> \"Success (main peak)\", \"Success (main peak)\", \"Succ…\n$ highpoint_metres   <dbl> 7937, 7937, 7937, 7000, 7160, 7000, 7250, 6400, 740…\n$ members            <dbl> 10, 10, 6, 2, 3, 6, 7, 19, 9, 5, 5, 5, 6, 4, 3, 4, …\n$ member_deaths      <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, …\n$ hired_staff        <dbl> 9, 0, 8, 0, 0, 2, 2, 0, 3, 0, 0, 3, 4, 2, 0, 2, 5, …\n$ hired_staff_deaths <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ oxygen_used        <lgl> TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…\n$ trekking_agency    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Kunga\"…\n\n\n\nglimpse(members)\n\nRows: 76,519\nColumns: 21\n$ expedition_id        <chr> \"AMAD78301\", \"AMAD78301\", \"AMAD78301\", \"AMAD78301…\n$ member_id            <chr> \"AMAD78301-01\", \"AMAD78301-02\", \"AMAD78301-03\", \"…\n$ peak_id              <chr> \"AMAD\", \"AMAD\", \"AMAD\", \"AMAD\", \"AMAD\", \"AMAD\", \"…\n$ peak_name            <chr> \"Ama Dablam\", \"Ama Dablam\", \"Ama Dablam\", \"Ama Da…\n$ year                 <dbl> 1978, 1978, 1978, 1978, 1978, 1978, 1978, 1978, 1…\n$ season               <chr> \"Autumn\", \"Autumn\", \"Autumn\", \"Autumn\", \"Autumn\",…\n$ sex                  <chr> \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\",…\n$ age                  <dbl> 40, 41, 27, 40, 34, 25, 41, 29, 35, 37, 23, 44, 2…\n$ citizenship          <chr> \"France\", \"France\", \"France\", \"France\", \"France\",…\n$ expedition_role      <chr> \"Leader\", \"Deputy Leader\", \"Climber\", \"Exp Doctor…\n$ hired                <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ highpoint_metres     <dbl> NA, 6000, NA, 6000, NA, 6000, 6000, 6000, NA, 681…\n$ success              <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ solo                 <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ oxygen_used          <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ died                 <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ death_cause          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ death_height_metres  <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ injured              <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ injury_type          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ injury_height_metres <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n\nGiven that each record is of a member of an expedition, how many different expeditions occurred, according to the datasets?\nFor expeditions, will each row be a unique expedition?\n\nexpeditions %>% count(expedition_id, sort=TRUE)\n\n# A tibble: 10,363 × 2\n   expedition_id     n\n   <chr>         <int>\n 1 KANG10101         2\n 2 ACHN15301         1\n 3 ACHN15302         1\n 4 ACHN18301         1\n 5 AMAD00101         1\n 6 AMAD00102         1\n 7 AMAD00103         1\n 8 AMAD00104         1\n 9 AMAD00105         1\n10 AMAD00106         1\n# … with 10,353 more rows\n\n\nSince KANG10101 appears twice, how do those rows appear?\n\nexpeditions %>%\n  filter(expedition_id==\"KANG10101\") %>%\n  datatable(options = list(dom = 't', scrollX = TRUE))\n\n\n\n\n\n\nThey are indeed two different expeditions, a century apart. How many other expeditions have missing values? I’ll use a function from the [naniar](https://naniar.njtierney.com/) package, which shows the number and percentage of missing values for each variable.\n\nnaniar::miss_var_summary(expeditions)\n\n# A tibble: 16 × 3\n   variable           n_miss pct_miss\n   <chr>               <int>    <dbl>\n 1 termination_date     2380 23.0    \n 2 trekking_agency      1580 15.2    \n 3 basecamp_date        1095 10.6    \n 4 highpoint_date        650  6.27   \n 5 highpoint_metres      414  3.99   \n 6 peak_name               1  0.00965\n 7 expedition_id           0  0      \n 8 peak_id                 0  0      \n 9 year                    0  0      \n10 season                  0  0      \n11 termination_reason      0  0      \n12 members                 0  0      \n13 member_deaths           0  0      \n14 hired_staff             0  0      \n15 hired_staff_deaths      0  0      \n16 oxygen_used             0  0      \n\n\nFor expeditions without a basecamp date, were the reasons?\n\nexpeditions %>%\n  filter(is.na(basecamp_date)) %>%\n  count(termination_reason)\n\n# A tibble: 15 × 2\n   termination_reason                                                          n\n   <chr>                                                                   <int>\n 1 Accident (death or serious injury)                                         39\n 2 Attempt rumoured                                                           12\n 3 Bad conditions (deep snow, avalanching, falling ice, or rock)              47\n 4 Bad weather (storms, high winds)                                           54\n 5 Did not attempt climb                                                     137\n 6 Did not reach base camp                                                    59\n 7 Illness, AMS, exhaustion, or frostbite                                     26\n 8 Lack (or loss) of supplies or equipment                                     7\n 9 Lack of time                                                                1\n10 Other                                                                     109\n11 Route technically too difficult, lack of experience, strength, or moti…    41\n12 Success (claimed)                                                           6\n13 Success (main peak)                                                       446\n14 Success (subpeak)                                                          20\n15 Unknown                                                                    91\n\n\nThough these trips did not happen in the end, they’re still considered expeditions and KANG10101 as two distinct expeditions. How does this ID appear in the members dataset? Are the two years present there too? (Yes.)\n\nmembers %>%\n  filter(expedition_id==\"KANG10101\")\n\n# A tibble: 7 × 21\n  exped…¹ membe…² peak_id peak_…³  year season sex     age citiz…⁴ exped…⁵ hired\n  <chr>   <chr>   <chr>   <chr>   <dbl> <chr>  <chr> <dbl> <chr>   <chr>   <lgl>\n1 KANG10… KANG10… KANG    Kangch…  1910 Spring M        41 UK      Leader  FALSE\n2 KANG10… KANG10… KANG    Kangch…  2010 Spring M        53 S Korea Leader  FALSE\n3 KANG10… KANG10… KANG    Kangch…  2010 Spring M        40 S Korea Climber FALSE\n4 KANG10… KANG10… KANG    Kangch…  2010 Spring M        47 S Korea Climber FALSE\n5 KANG10… KANG10… KANG    Kangch…  2010 Spring M        30 S Korea Climber FALSE\n6 KANG10… KANG10… KANG    Kangch…  2010 Spring M        27 Nepal   H-A Wo… TRUE \n7 KANG10… KANG10… KANG    Kangch…  2010 Spring M        39 Nepal   H-A Wo… TRUE \n# … with 10 more variables: highpoint_metres <dbl>, success <lgl>, solo <lgl>,\n#   oxygen_used <lgl>, died <lgl>, death_cause <chr>,\n#   death_height_metres <dbl>, injured <lgl>, injury_type <chr>,\n#   injury_height_metres <dbl>, and abbreviated variable names ¹​expedition_id,\n#   ²​member_id, ³​peak_name, ⁴​citizenship, ⁵​expedition_role\n\n\nIs every expedition listed in expeditions also in members? I’ll use the setdiff() function to see if any IDs from expeditions are not found in members.\n\nsetdiff(expeditions$expedition_id, members$expedition_id)\n\n [1] \"ANN186305\" \"CHEO87301\" \"DHA149001\" \"EVER68101\" \"EVER79102\" \"GAUR73301\"\n [7] \"KGUR65101\" \"MAKA34101\" \"MANA70301\" \"YALU65101\" \"YALU67101\" \"EVER65102\"\n[13] \"EVER19185\"\n\n\nThere are 13. Any particular commonalities between those expeditions?\n\nexpeditions_only <- setdiff(expeditions$expedition_id, members$expedition_id) # creates a character string\n\nexpeditions %>% \n  filter(expedition_id %in% expeditions_only)\n\n# A tibble: 13 × 16\n   exped…¹ peak_id peak_…²  year season basecamp…³ highpoin…⁴ terminat…⁵ termi…⁶\n   <chr>   <chr>   <chr>   <dbl> <chr>  <date>     <date>     <date>     <chr>  \n 1 ANN186… ANN1    Annapu…  1986 Autumn NA         NA         NA         Did no…\n 2 CHEO87… CHEO    Cheo H…  1987 Autumn NA         NA         NA         Did no…\n 3 DHA149… DHA1    Dhaula…  1949 Unkno… NA         NA         NA         Attemp…\n 4 EVER68… EVER    Everest  1968 Spring NA         NA         NA         Attemp…\n 5 EVER79… EVER    Everest  1979 Spring NA         NA         NA         Did no…\n 6 GAUR73… GAUR    Gauris…  1973 Autumn NA         NA         NA         Did no…\n 7 KGUR65… KGUR    Kang G…  1965 Spring NA         NA         NA         Attemp…\n 8 MAKA34… MAKA    Makalu   1934 Spring NA         NA         NA         Did no…\n 9 MANA70… MANA    Manaslu  1970 Autumn NA         NA         NA         Did no…\n10 YALU65… YALU    Yalung…  1965 Spring NA         NA         NA         Did no…\n11 YALU67… YALU    Yalung…  1967 Spring NA         NA         NA         Did no…\n12 EVER65… EVER    Everest  1965 Spring NA         NA         NA         Attemp…\n13 EVER19… EVER    Everest  2019 Spring NA         2019-05-22 NA         Succes…\n# … with 7 more variables: highpoint_metres <dbl>, members <dbl>,\n#   member_deaths <dbl>, hired_staff <dbl>, hired_staff_deaths <dbl>,\n#   oxygen_used <lgl>, trekking_agency <chr>, and abbreviated variable names\n#   ¹​expedition_id, ²​peak_name, ³​basecamp_date, ⁴​highpoint_date,\n#   ⁵​termination_date, ⁶​termination_reason\n\n# ANN186305\n\nThe expeditions range from 1924 through the 1980s, and one from 2019. That one from 2019 is the only successful trip (termination date not available possibly due to it occurring after the end date of the dataset timeframe) while the rest were either rumored attempts or climbs that were not attempted, with one expedition not reaching the base camp.\nAny IDs found in members but not in expeditions? (No)\n\nsetdiff(members$expedition_id, expeditions$expedition_id)\n\ncharacter(0)\n\n\nTherefore, the number of unique expedition IDs in the members data (which has a total 76,519 rows) should be 13 less than number of unique observations in the expeditions data (which, as found earlier, has 10,364 with one “duplicate” ID).\n\nmembers %>%\n  count(expedition_id, sort=TRUE)\n\n# A tibble: 10,350 × 2\n   expedition_id     n\n   <chr>         <int>\n 1 EVER88101        99\n 2 HIML13308        90\n 3 EVER15106        79\n 4 EVER08101        76\n 5 MANA16304        71\n 6 EVER18185        69\n 7 EVER73101        68\n 8 EVER13181        65\n 9 EVER19117        65\n10 EVER17110        64\n# … with 10,340 more rows\n\n\nGoing forward, I’ll focus on the year, season, age, citizenship and gender variables in creating the visualizations. The expedition role specifies the titles of each individuals, with the most commons ones being climber, H-A worker, leader, expedition doctor and deputy leader. In this post all individuals will be referred to as climbers.\n\nSeasons and decades\nDo the expeditions tend to occur during certain seasons and has that been the case throughout the decades?\n\nexpeditions %>%\n  mutate(decade = case_when(\n    year >= \"1900\" & year <= \"1909\" ~ \"1900-'09\",\n    year >= \"1910\" & year <= \"1919\" ~ \"'10-'19\",\n    year >= \"1920\" & year <= \"1929\" ~ \"'20-'29\",\n    year >= \"1930\" & year <= \"1939\" ~ \"'30-'39\",\n    year >= \"1940\" & year <= \"1949\" ~ \"'40-'49\",\n    year >= \"1950\" & year <= \"1959\" ~ \"'50-'59\",\n    year >= \"1960\" & year <= \"1969\" ~ \"'60-'69\",\n    year >= \"1970\" & year <= \"1979\" ~ \"'70-'79\",\n    year >= \"1980\" & year <= \"1989\" ~ \"'80-'89\",\n    year >= \"1990\" & year <= \"1999\" ~ \"'90-'99\",\n    year >= \"2000\" & year <= \"2009\" ~ \"2000-'09\",\n    year >= \"2010\" & year <= \"2019\" ~ \" '10-'19 \",\n    TRUE ~ \"Unknown\")) %>%\n  mutate(year = lubridate::ymd(year, truncated = 2L)) %>%\n  filter(season != \"Unknown\") %>%\n  mutate(season = factor(season, levels=c(\"Winter\", \"Spring\", \"Summer\", \"Autumn\"))) %>%\n  mutate(decade = factor(decade, levels=c(\"1900-'09\", \"'10-'19\", \"'20-'29\", \"'30-'39\", \"'40-'49\", \"'50-'59\", \"'60-'69\", \"'70-'79\", \"'80-'89\", \"'90-'99\", \"2000-'09\", \" '10-'19 \"))) %>%\n  ggplot(aes(decade, ..count.., fill = season)) +\n    geom_bar(width = 0.7, alpha = 0.9) +\n    scale_y_continuous(expand = c(0,0), labels = scales::comma_format()) +\n    scale_fill_manual(values=c(\"#4e89ae\", \"#fe7171\", \"#f0a500\", \"#7ea04d\")) +\n    annotate(\"text\", label = \"Winter expeditions\\npeaked in the '80s\",\n             x = 5, y = 1150, size = 3.5, color = \"#4e89ae\", family=\"Commissioner\", hjust = 0) +\n    geom_segment(aes(x = 7.5, y = 1140, xend = 8.4, yend = 1140),\n                 size = 0.45, color = \"#4e89ae\",\n                 arrow = arrow(length = unit(1.5, \"mm\"))) +\n    annotate(\"text\", label = \"In the '80s and '90s,\\nautumn expeditions\\noutnumbered those\\nin the spring\", \n             x = 7.5, y = 2200, size = 3.5, color = \"#7ea04d\", family=\"Commissioner\", hjust = 0) +\n    theme_linedraw() +\n    theme(plot.title = element_text(face=\"bold\"),\n                   plot.title.position = \"plot\",\n                   plot.background = element_rect(fill = \"#fff7f5\", color = NA),\n                   legend.position = \"top\", \n                   legend.justification = \"left\",\n                   legend.direction = \"horizontal\",\n                   legend.background = element_rect(fill = \"#fff7f5\", color = NA),\n                   legend.text = element_text(margin = margin(r = 0.28, unit = 'cm'), size = 10),\n                   legend.box.margin = margin(c(0,0,0,-54)),\n                   text = element_text(family = \"Commissioner\"),\n                   panel.grid.major.x = element_blank(),\n                   panel.grid.minor.x = element_blank()) +\n    labs(x = NULL,\n         y = \"Number of expeditions\",\n         title = \"Slight Seasonal Shifts Over Decades of Expeditions\",\n         subtitle = \"Expeditions span 1905-2019\",\n         fill = NULL,\n         caption = \"Source: #TidyTuesday | Himalayan Database\")\n\n\n\n\nRather than relying solely on eyeballing the seasonal proportions, here are the actual percentages listed in tabular form (using the DT package). Now it’s clear more spring expeditions occurred in every decade except for the 1980s and 1990s, during which the autumn months dominated.\n\nlibrary(DT)\n\nexpeditions %>%\n  mutate(decade = case_when(\n    year >= \"1900\" & year <= \"1909\" ~ \"1900-1909\",\n    year >= \"1910\" & year <= \"1919\" ~ \"1910-1919\",\n    year >= \"1920\" & year <= \"1929\" ~ \"1920-1929\",\n    year >= \"1930\" & year <= \"1939\" ~ \"1930-1939\",\n    year >= \"1940\" & year <= \"1949\" ~ \"1940-1949\",\n    year >= \"1950\" & year <= \"1959\" ~ \"1950-1959\",\n    year >= \"1960\" & year <= \"1969\" ~ \"1960-1969\",\n    year >= \"1970\" & year <= \"1979\" ~ \"1970-1979\",\n    year >= \"1980\" & year <= \"1989\" ~ \"1980-1989\",\n    year >= \"1990\" & year <= \"1999\" ~ \"1990-1999\",\n    year >= \"2000\" & year <= \"2009\" ~ \"2000-2009\",\n    year >= \"2010\" & year <= \"2019\" ~ \"2010-2019 \",\n    TRUE ~ \"Unknown\")) %>%\n  mutate(year = lubridate::ymd(year, truncated = 2L)) %>%\n  filter(season != \"Unknown\") %>%\n  count(decade, season) %>%\n  group_by(decade) %>%\n  mutate(pct = round((n/sum(n)*100), digits=1)) %>%\n  ungroup() %>%\n  select(-n) %>%\n  spread(season, pct) %>% \n  select(Deacde = decade, Winter, Spring, Summer, Autumn) %>%\n  mutate(Winter = replace_na(Winter, \"-\")) %>%\n  mutate(Spring = replace_na(Spring, \"-\")) %>%\n  mutate(Summer = replace_na(Summer, \"-\")) %>%\n  mutate(Autumn = replace_na(Autumn, \"-\")) %>% \n  datatable(options = list(dom = 't',\n                           pageLength = nrow(.)))\n\n\n\n\n\n\nThe rest of the charts focus on the citizenship variable which lists the country or countries of origin for the climbers. Only 10 out of the more than 76,500 expeditions do not have a country or countries listed for the climber. The charts do not include individuals with more than one country of citizenship listed.\nFirst, I’m creating a custom theme (based on the bar chart above) that I’ll use in addition to theme_linedraw().\n\ntheme_him <- theme_linedraw() + theme(plot.title = element_text(face=\"bold\"),\n                   plot.title.position = \"plot\",\n                   plot.background = element_rect(fill = \"#fff7f5\", color = NA),\n                   legend.position = \"top\", \n                   legend.justification = \"left\",\n                   legend.direction = \"horizontal\",\n                   legend.background = element_rect(fill = \"#fff7f5\", color = NA),\n                   legend.text = element_text(margin = margin(r = 0.28, unit = 'cm'), size = 10),\n                   legend.box.margin = margin(c(0,0,0,-77)),\n                   text = element_text(family = \"Commissioner\"),\n                   axis.title = element_text(size = 10),\n                   panel.grid.major.y = element_blank(),\n                   panel.grid.minor.y = element_blank())\n\nDo expeditions tend to happen during certain seasons?\n\nmembers %>%\n  count(citizenship, season, sort=T) %>%\n  group_by(citizenship) %>%\n  filter(sum(n) > 500) %>% # filter by countries with total climbers > 500\n  mutate(n_country = sum(n)) %>%\n  ungroup() %>%\n  mutate(season = factor(season, levels=c(\"Winter\", \"Spring\", \"Summer\", \"Autumn\", \"Unknown\"))) %>%\n  mutate(citizenship = fct_reorder(citizenship, n_country)) %>%\n  ggplot(aes(citizenship, n, fill = season)) +\n    geom_col(position = position_stack(reverse = TRUE)) +\n    scale_y_continuous(expand = c(0,0), labels = scales::comma_format()) +\n    scale_fill_manual(values=c(\"#4e89ae\", \"#fe7171\", \"#f0a500\", \"#7ea04d\", \"#d2d3c9\")) +\n    # Japan\n    annotate(\"text\", label = \"In addition to higher than average winter trips,\\nclimbers with Japanese citizenship make the\\nmost summer trips.\",\n             x = 20.5, y = 8000, size = 3.25, color = \"#f0a500\", family=\"Commissioner\", hjust = 0) +\n    geom_segment(aes(x = 21, y = 7700, xend = 21, yend = 6700),\n                 size = 0.45, color = \"#f0a500\",\n                 arrow = arrow(length = unit(1.5, \"mm\"))) +\n    # France\n    annotate(\"text\", label = \"France has a disproportionately high\\nnumber of autumn expeditions.\",\n             x = 18.65, y = 6100, size = 3.25, color = \"#7ea04d\", family=\"Commissioner\", hjust = 0) +\n    geom_segment(aes(x = 19, y = 5900, xend = 19, yend = 4900),\n                 size = 0.45, color = \"#7ea04d\",\n                 arrow = arrow(length = unit(1.5, \"mm\"))) +\n    # South Korea\n    annotate(\"text\", label = \"South Korea has a notably high number\\n(and proportion) of climbers involved\\nin winter expeditions, followed by fellow\\nAsian countries Japan and Nepal.\",\n             x = 15.95, y = 4500, size = 3.25, color = \"#4e89ae\", family=\"Commissioner\", hjust = 0) +\n    geom_segment(aes(x = 17, y = 4200, xend = 17, yend = 3200),\n                 size = 0.45, color = \"#4e89ae\",\n                 arrow = arrow(length = unit(1.5, \"mm\"))) +\n    # India\n    annotate(\"text\", label = \"India stands out for its unusually\\nhigh proportion of climbers making the \\ntrip in the spring, similar to Russia.\",\n             x = 10.5, y = 3600, size = 3.25, color = \"#fe7171\", family=\"Commissioner\", hjust = 0) +\n    geom_segment(aes(x = 11, y = 3275, xend = 11, yend = 2275),\n                 size = 0.45, color = \"#fe7171\",\n                 arrow = arrow(length = unit(1.5, \"mm\"))) +\n    theme_him +\n    labs(x = NULL,\n         y = \"Number of expeditions\",\n         title = \"Expeditions by Season and Country\",\n         subtitle = \"Includes countries with more than 500 climbers\",\n         fill = NULL,\n         caption = \"Source: #TidyTuesday | Himalayan Database\") +\n    coord_flip()\n\n\n\n\nWhile the earlier chart showed that overall, more expeditions occurred in the spring, breaking the data down by countries reveals distinctions, as noted above.\n\n\nTrips by decades\nThe next bar chart visualizes the number of trips per 20-year time frames. While the majority of the countries with at least 500 climbers had the largest proportion of trips occur in 2000-2019, take a look at those that did not.\n\nmembers %>%\n  mutate(decade = case_when(\n    year >= \"1900\" & year <= \"1919\" ~ \"1900-1919\",\n    year >= \"1920\" & year <= \"1939\" ~ \"1920-1939\",\n    year >= \"1940\" & year <= \"1959\" ~ \"1940-1959\",\n    year >= \"1960\" & year <= \"1979\" ~ \"1960-1979\",\n    year >= \"1980\" & year <= \"1999\" ~ \"1980-1999\",\n    year >= \"2000\" & year <= \"2019\" ~ \"2000-2019\",\n    TRUE ~ \"NA\")) %>%\n  count(citizenship, decade, sort=T) %>%\n  group_by(citizenship) %>%\n  filter(sum(n) > 500) %>%\n  mutate(n_country = sum(n)) %>%\n  ungroup() %>%\n  mutate(citizenship = fct_reorder(citizenship, n_country)) %>%\n  ggplot(aes(citizenship, n, fill = decade)) +\n    geom_col(position = position_stack(reverse = TRUE)) +\n    scale_y_continuous(expand = c(0,0), labels = scales::comma_format()) +\n    scale_fill_manual(values = PNWColors::pnw_palette(name = \"Sailboat\", n = 6, type = \"discrete\")) +\n    # Japan\n    annotate(\"text\", label = \"An unusually large number of Japanese\\nclimbers made the trek in 1960-1979.\\nJapan also has the distinction of being\\nthe only country here with more trips\\nmade in 1980-1999 than in 2000-2019.\",\n             x = 19.65, y = 8000, size = 3.25, color = \"#f0a500\", family=\"Commissioner\", hjust = 0) +\n    geom_segment(aes(x = 21, y = 7700, xend = 21, yend = 6700),\n                 size = 0.45, color = \"#f0a500\",\n                 arrow = arrow(length = unit(1.5, \"mm\"))) +\n    # South Korea\n    annotate(\"text\", label = \"Along with France, Spain and Switzerland,\\nSouth Korea has a comparable share of\\nclimbers who made the trip in 1980-1999\\nand 2000-2019.\",\n             x = 16, y = 4500, size = 3.25, color = \"#E89C81\", family=\"Commissioner\", hjust = 0) +\n    geom_segment(aes(x = 17, y = 4200, xend = 17, yend = 3200),\n                 size = 0.45, color = \"#E89C81\",\n                 arrow = arrow(length = unit(1.5, \"mm\"))) +\n    # China\n    annotate(\"text\", label = \"China, and Nepal (for very different reasons),\\nhave the largest proportions of trip made\\nin 2000-2019.\",\n             x = 12.3, y = 3750, size = 3.25, color = \"#D2848D\", family=\"Commissioner\", hjust = 0) +\n    geom_segment(aes(x = 13, y = 3500, xend = 13, yend = 2500),\n                 size = 0.45, color = \"#D2848D\",\n                 arrow = arrow(length = unit(1.5, \"mm\"))) +\n    theme_him +\n    labs(x = NULL,\n         y = \"Number of Expeditions\",\n         title = \"Expeditions by Decades and Country\",\n         subtitle = \"Includes countries with more than 500 climbers\",\n         fill = NULL,\n         caption = \"Source: #TidyTuesday | Himalayan Database\") +\n    coord_flip()\n\n\n\n\nHere are the specific percentages by decade. About half the trips recorded in the dataset occurred between 2000 and 2019.\n\nmembers %>%\n  mutate(decade = case_when(\n    year >= \"1900\" & year <= \"1909\" ~ \"1900-1909\",\n    year >= \"1910\" & year <= \"1919\" ~ \"1910-1919\",\n    year >= \"1920\" & year <= \"1929\" ~ \"1920-1929\",\n    year >= \"1930\" & year <= \"1939\" ~ \"1930-1939\",\n    year >= \"1940\" & year <= \"1949\" ~ \"1940-1949\",\n    year >= \"1950\" & year <= \"1959\" ~ \"1950-1959\",\n    year >= \"1960\" & year <= \"1969\" ~ \"1960-1969\",\n    year >= \"1970\" & year <= \"1979\" ~ \"1970-1979\",\n    year >= \"1980\" & year <= \"1989\" ~ \"1980-1989\",\n    year >= \"1990\" & year <= \"1999\" ~ \"1990-1999\",\n    year >= \"2000\" & year <= \"2009\" ~ \"2000-2009\",\n    year >= \"2010\" & year <= \"2019\" ~ \"2010-2019\",\n    TRUE ~ \"NA\")) %>%\n  count(decade, sort=T) %>%\n  mutate(pct = round(n/sum(n)*100, digit=1))\n\n# A tibble: 12 × 3\n   decade        n   pct\n   <chr>     <int> <dbl>\n 1 2010-2019 24832  32.5\n 2 2000-2009 21327  27.9\n 3 1990-1999 13746  18  \n 4 1980-1989 10371  13.6\n 5 1970-1979  3709   4.8\n 6 1960-1969  1161   1.5\n 7 1950-1959   953   1.2\n 8 1930-1939   266   0.3\n 9 1920-1929    70   0.1\n10 1940-1949    68   0.1\n11 1900-1909    13   0  \n12 1910-1919     3   0  \n\n\n\n\nAge factor\nAsian countries continue to divert from the overall trends of the group of countries, particularly in the case of climber age. Missing values, which for the age variable make up about 4.6%, have been excluded from the chart. Unsurprisingly, the 25-34 and 35-44 age groups make up the largest proportions.\n\nmembers %>%\n  mutate(age_range = case_when(\n    age <= \"17\" ~ \"Under 18\",\n    age >= \"18\" & age <= \"24\" ~ \"18-24\",\n    age >= \"25\" & age <= \"34\" ~ \"25-34\",\n    age >= \"35\" & age <= \"44\" ~ \"35-44\",\n    age >= \"45\" & age <= \"54\" ~ \"45-54\",\n    age >= \"55\" & age <= \"64\" ~ \"55-64\",\n    age >= \"65\" ~ \"65+\",\n    TRUE ~ \"Unknown\")) %>%\n  filter(age_range != \"Unknown\") %>%\n  count(citizenship, age_range, sort=T) %>%\n  group_by(citizenship) %>%\n  filter(sum(n) > 500) %>%\n  mutate(n_country = sum(n)) %>%\n  ungroup() %>%\n  mutate(age_range = factor(age_range, levels=c(\"Under 18\", \"18-24\", \"25-34\", \"35-44\", \"45-54\", \"55-64\", \"65+\"))) %>%\n  mutate(citizenship = fct_reorder(citizenship, n_country)) %>%\n  ggplot(aes(citizenship, n, fill = age_range)) +\n    geom_col(position = position_stack(reverse = TRUE)) +\n    scale_y_continuous(expand = c(0,0), labels = scales::comma_format()) +\n    paletteer::scale_fill_paletteer_d(\"awtools::a_palette\", direction = 1) +\n    # Japan\n    annotate(\"text\", label = \"Japanese make up the majority\\nof climbers 65+\",\n             x = 20.7, y = 7800, size = 3.25, color = \"#E74A60\", family=\"Commissioner\", hjust = 0) +\n    geom_segment(aes(x = 21, y = 7500, xend = 21, yend = 6500),\n                 size = 0.45, color = \"#E74A60\",\n                 arrow = arrow(length = unit(1.5, \"mm\"))) +\n    # India\n    annotate(\"text\", label = \"India, along with fellow Asian countries\\nChina, South Korea, Japan and Nepal,\\nhave a noticeably higher proportion of\\nclimbers 18-24 years of age\",\n             x = 9.9, y = 3300, size = 3.25, color = \"#2B363C\", family=\"Commissioner\", hjust = 0) +\n    geom_segment(aes(x = 11, y = 3000, xend = 11, yend = 2000),\n                 size = 0.45, color = \"#2B363C\",\n                 arrow = arrow(length = unit(1.5, \"mm\"))) +\n    theme_him +\n    labs(y = \"Number of expeditions\",\n         x = NULL,\n         title = \"Expeditions by Age Group and Country\",\n         subtitle = \"Includes countries with more than 500 climbers\",\n         fill = NULL,\n         caption = \"Source: #TidyTuesday | Himalayan Database\") +\n    coord_flip()\n\n\n\n\n\nGiven the age distinction with Japan, out of all of the country’s climbers, how many, percentage-wise, are older than 65? 6% (To put the number in perspective, the table includes countries with percentages > 1 and number of expeditions > 9. )\n\nmembers %>%\n  mutate(age_range = case_when(\n    age <= \"17\" ~ \"Under 18\",\n    age >= \"18\" & age <= \"24\" ~ \"18-24\",\n    age >= \"25\" & age <= \"34\" ~ \"25-34\",\n    age >= \"35\" & age <= \"44\" ~ \"35-44\",\n    age >= \"45\" & age <= \"54\" ~ \"45-54\",\n    age >= \"55\" & age <= \"64\" ~ \"55-64\",\n    age >= \"65\" ~ \"65+\",\n    TRUE ~ \"Unknown\")) %>%\n  filter(age_range != \"Unknown\") %>%\n  count(citizenship, age_range, sort=T) %>%\n  group_by(citizenship) %>%\n  mutate(pct = round(n/sum(n)*100)) %>%\n  ungroup() %>%\n  filter(age_range == \"65+\" & pct > 1 & n > 9) %>%\n  arrange(desc(pct)) %>%\n  select(-age_range)\n\n# A tibble: 6 × 3\n  citizenship     n   pct\n  <chr>       <int> <dbl>\n1 Japan         342     6\n2 USA           110     2\n3 France         69     2\n4 Germany        48     2\n5 Russia         23     2\n6 Slovenia       11     2\n\n\n\nFramed another way, what percentage of all climbers older than 65 are Japanese? 38.7% (The table includes the countries with the 10 highest percentages.)\n\nmembers %>%\n  mutate(age_range = case_when(\n    age <= \"17\" ~ \"Under 18\",\n    age >= \"18\" & age <= \"24\" ~ \"18-24\",\n    age >= \"25\" & age <= \"34\" ~ \"25-34\",\n    age >= \"35\" & age <= \"44\" ~ \"35-44\",\n    age >= \"45\" & age <= \"54\" ~ \"45-54\",\n    age >= \"55\" & age <= \"64\" ~ \"55-64\",\n    age >= \"65\" ~ \"65+\",\n    TRUE ~ \"Unknown\")) %>%\n  filter(age_range != \"Unknown\") %>%\n  count(citizenship, age_range, sort=T) %>%\n  filter(age_range == \"65+\") %>%\n  mutate(pct_65 = round(n/sum(n)*100, digits=1)) %>%\n  select(-age_range) %>%\n  head(10)\n\n# A tibble: 10 × 3\n   citizenship     n pct_65\n   <chr>       <int>  <dbl>\n 1 Japan         342   38.7\n 2 USA           110   12.4\n 3 France         69    7.8\n 4 Germany        48    5.4\n 5 UK             48    5.4\n 6 Italy          33    3.7\n 7 Austria        28    3.2\n 8 Spain          28    3.2\n 9 Russia         23    2.6\n10 Switzerland    22    2.5\n\n\n\nOn the other end of the age spectrum, what percentage of climbers 18-24 years of age come from Asian countries? 66% (The table includes only countries where 18-24 year olds make up at least 1% of climbers.)\n\nmembers %>%\n  mutate(age_range = case_when(\n    age <= \"17\" ~ \"Under 18\",\n    age >= \"18\" & age <= \"24\" ~ \"18-24\",\n    age >= \"25\" & age <= \"34\" ~ \"25-34\",\n    age >= \"35\" & age <= \"44\" ~ \"35-44\",\n    age >= \"45\" & age <= \"54\" ~ \"45-54\",\n    age >= \"55\" & age <= \"64\" ~ \"55-64\",\n    age >= \"65\" ~ \"65+\",\n    TRUE ~ \"Unknown\")) %>%\n  filter(age_range != \"Unknown\") %>%\n  count(citizenship, age_range, sort=T) %>%\n  filter(age_range == \"18-24\") %>%\n  mutate(pct_1824 = round(n/sum(n)*100)) %>%\n  filter(citizenship %in% c(\"Bangladesh\", \"Bhutan\", \"China\", \"India\", \"Indonesia\", \"Iran\", \"Israel\", \"Japan\", \"Kazakhstan\", \"Kuwait\", \"Malaysia\", \"Nepal\", \"Pakistan\", \"S Korea\", \"Singapore\", \"Taiwan\", \"Uzbekistan\", \"Vietnam\") & pct_1824 >= 1) %>%\n  select(-age_range)\n\n# A tibble: 6 × 3\n  citizenship     n pct_1824\n  <chr>       <int>    <dbl>\n1 Nepal        1956       34\n2 Japan         761       13\n3 S Korea       388        7\n4 China         378        7\n5 India         231        4\n6 Iran           32        1\n\n\n\nAre Asian countries indeed the ones with the highest percentages of climbers 18-24 years of age? Yes, China leads the list with 20% of its climbers within the age group, while Slovenia is the only non-Asian country in which the age group makes up a double-digit percentage, at 11%. Countries with trips numbering fewer than 10 have been removed from the list.\n\nmembers %>%\n  mutate(age_range = case_when(\n    age <= \"17\" ~ \"Under 18\",\n    age >= \"18\" & age <= \"24\" ~ \"18-24\",\n    age >= \"25\" & age <= \"34\" ~ \"25-34\",\n    age >= \"35\" & age <= \"44\" ~ \"35-44\",\n    age >= \"45\" & age <= \"54\" ~ \"45-54\",\n    age >= \"55\" & age <= \"64\" ~ \"55-64\",\n    age >= \"65\" ~ \"65+\",\n    TRUE ~ \"Unknown\")) %>%\n  filter(age_range != \"Unknown\") %>%\n  count(citizenship, age_range, sort=T) %>%\n  group_by(citizenship) %>%\n  mutate(pct = round(n/sum(n)*100)) %>%\n  ungroup() %>%\n  filter(age_range == \"18-24\" & n > 9) %>%\n  arrange(desc(pct)) %>%\n  select(-age_range) %>%\n  head(10)\n\n# A tibble: 10 × 3\n   citizenship     n   pct\n   <chr>       <int> <dbl>\n 1 Indonesia      27    31\n 2 China         378    20\n 3 Malaysia       22    16\n 4 Yugoslavia     75    15\n 5 Nepal        1956    14\n 6 S Korea       388    13\n 7 India         231    13\n 8 Japan         761    12\n 9 Slovenia       64    11\n10 Iran           32    10\n\n\n\nHow many climbers in the dataset are under 18? Out of 76,519 expeditions, 124 of them were undertaken teenagers, while two are even younger at the age of 7 (Italian, 1984) and 12 (Nepalese, 1984). See the breakdown by age group.\n\nmembers %>%\n  mutate(age_range = case_when(\n    age <= 17 ~ \"Under 18\",\n    age >= 18 & age <= \"24\" ~ \"18-24\",\n    age >= 25 & age <= \"34\" ~ \"25-34\",\n    age >= 35 & age <= \"44\" ~ \"35-44\",\n    age >= 45 & age <= \"54\" ~ \"45-54\",\n    age >= 55 & age <= \"64\" ~ \"55-64\",\n    age >= 65 ~ \"65+\",\n    TRUE ~ \"Unknown\")) %>%\n  filter(age_range != \"Unknown\") %>%\n  count(age_range, sort=T) %>%\n  mutate(pct = n/sum(n)*100)\n\n# A tibble: 7 × 3\n  age_range     n    pct\n  <chr>     <int>  <dbl>\n1 25-34     27199 37.2  \n2 35-44     22778 31.2  \n3 45-54     11963 16.4  \n4 18-24      5804  7.95 \n5 55-64      4269  5.85 \n6 65+         883  1.21 \n7 Under 18    126  0.173\n\n\n\n\nWomen Climbers\nThe final visualization looks at the percentage of expeditions taken by women, by country while also giving an overview of the countries (that have had women climbers) represented in the dataset.\nThis code sets up a world map base layer using the rnaturalearth package.\n\nlibrary(rnaturalearth)\n\nworld_map <- ne_countries(scale=\"medium\",\n                    type=\"countries\",\n                    returnclass=\"sf\")\n\nggplot() +\n  geom_sf(data=world_map, size=0.25, fill=\"#fafafa\") +\n  theme_void()\n\n\n\n\nThe following produces a dataframe showing the percentage of expeditions by women, based on country. Only countries with at least 10 women are included. I’ll join this subset with the map data.\n\nexpeditions_women <- members %>%\n  mutate(sex = ifelse(sex == \"F\", \"Women\", \"Men\")) %>%\n  filter(sex != \"NA\") %>%\n  count(citizenship, sex) %>%\n  group_by(citizenship) %>%\n  mutate(pct = round(n/sum(n)*100)) %>%\n  ungroup() %>%\n  mutate(sex = factor(sex, levels=c(\"Men\", \"Women\"))) %>%\n  filter(sex==\"Women\" & n > 9 & !str_detect(citizenship, \"/\")) # remove dual-country citizenship\n\nNow checking for which country names do not match and thus have to be edited in the expeditions_women dataframe, using setdiff(). This line asks: What country names in the citizenship column of the subset are not in the country names in the map data?\n\nsetdiff(expeditions_women$citizenship, world_map$geounit)\n\n[1] \"Czechoslovakia\" \"S Africa\"       \"S Korea\"        \"UK\"            \n[5] \"USA\"            \"W Germany\"      \"Yugoslavia\"    \n\n\nBased on the results, I’m removing the country names that no longer exist and renaming the rest.\n\nexpeditions_women <- expeditions_women %>%\n  # removing country names that no longer exist\n  filter(!str_detect(citizenship, \"Czechoslovakia|USSR|W Germany|Yugoslavia\")) %>%\n  # renaming countries\n  mutate(citizenship = str_replace_all(\n    citizenship,\n    c(\n      \"Bosnia-Herzegovina\" = \"Bosnia and Herzegovina\",\n      \"S Africa\" = \"South Africa\",\n      \"S Korea\" = \"South Korea\",\n      \"Serbia\" = \"Republic of Serbia\",\n      \"UK\" = \"United Kingdom\",\n      \"USA\" = \"United States of America\"\n    )\n  ))\n\n# check > should have no results\nsetdiff(expeditions_women$citizenship, world_map$geounit)\n\ncharacter(0)\n\n\nHere is a table of the final 49 countries, sorted by the percentage of expeditions involving women.\n\nexpeditions_women %>%\n  arrange(desc(pct)) %>%\n  select(-sex) %>%\n  select(Citizenship=citizenship, `# of expeditions, women`=n, `% of all expeditions`=pct) %>%\n  datatable()\n\n\n\n\n\n\nWith the exception of Norway, the countries where women make up more than 20% of the expeditions have relatively low numbers, with the number of women under 50. Most of them also happen to be small countries, area-wise, so they are not immediately visible on the map. Instead, you see swaths of yellow with subtle variations, signifying percentages of expeditions with women in the teens or lower.\n\n# join map layer with countries in Himalayan dataset\nexpeditions_women_maplayer <- world_map %>%\n  right_join(expeditions_women, by=c(\"geounit\"=\"citizenship\"))\n\nmap <- ggplot() +\n  geom_sf(data=world_map, size=0.25, color=\"#888888\", fill=\"#f9f9f9\") +\n  geom_sf(data=expeditions_women_maplayer, size=0.25, color=\"#888888\", aes(fill=pct)) +\n  scale_fill_gradient(low = \"#ffff3f\", high = \"#007f5f\") +\n  theme_void() +\n  theme(plot.title = element_text(face=\"bold\"),\n        plot.title.position = \"plot\",\n        legend.position = \"top\", \n        legend.justification = \"center\",\n        legend.direction = \"horizontal\",\n        text = element_text(family = \"Commissioner\"),\n        panel.background = element_rect(fill = \"#fff7f5\", color = NA),\n        legend.spacing.x = unit(0.4, 'cm')) +\n  guides(fill = guide_colorbar(title.vjust = 0.75, barheight = 1)) +\n  labs(fill=\"% of Women\",\n       title=\"Expeditions Undertaken by Women\",\n       subtitle=\"Includes countries with at least 10 expeditions by women\\n\",\n       caption = \"Source: #TidyTuesday | Himalayan Database\")\n\n# completely fill background with specified page color (eliminating white bands as happened when only running the plot)\n# https://gis.stackexchange.com/questions/269224/ggplot2-map-with-colored-background-and-coord-map\ncowplot::ggdraw(map) + \n  theme(plot.background = element_rect(fill=\"#fff7f5\", color = NA))\n\n\n\n\nA larger map would improve the visibility of the smaller countries but given the format constraints of this page, I’ll try grouping the percentages and using more distinct colors for the ramp.\n\n# range of % values\nexpeditions_women %>%\n  summary()\n\n citizenship           sex           n              pct       \n Length:49          Men  : 0   Min.   : 10.0   Min.   : 1.00  \n Class :character   Women:49   1st Qu.: 19.0   1st Qu.: 9.00  \n Mode  :character              Median : 46.0   Median :13.00  \n                               Mean   :137.3   Mean   :15.57  \n                               3rd Qu.:191.0   3rd Qu.:16.00  \n                               Max.   :806.0   Max.   :83.00  \n\n\nPercentages run from 1-83 but was is the distribution (in order to know the which percentage groups to make)?\n\nexpeditions_women %>%\n  ggplot(aes(x=pct)) +\n    geom_histogram(stat=\"count\", alpha=0.8, fill=\"#333C83\") +\n    scale_y_continuous(expand = c(0, 0)) +\n    theme_him\n\nWarning in geom_histogram(stat = \"count\", alpha = 0.8, fill = \"#333C83\"):\nIgnoring unknown parameters: `binwidth`, `bins`, and `pad`\n\n\n\n\n\nWith most of the percentages clustered under 20, I’ll create the groups as follows:\n\nexp_women_v2 <- expeditions_women %>%\n  mutate(pct_group = case_when(\n    pct <= 10 ~ \"1-10\",\n    pct > 10 & pct <= 20 ~ \"11-20\",\n    pct > 20 ~ \"More than 20\")) %>%\n  # to set order for colors\n  mutate(pct_group = factor(pct_group, levels=c(\"1-10\", \"11-20\", \"More than 20\")))\n\nexp_women_v2\n\n# A tibble: 49 × 5\n   citizenship sex       n   pct pct_group   \n   <chr>       <fct> <int> <dbl> <fct>       \n 1 Andorra     Women    11    35 More than 20\n 2 Argentina   Women    14     6 1-10        \n 3 Australia   Women   191    13 11-20       \n 4 Austria     Women   220    10 1-10        \n 5 Belgium     Women    60    13 11-20       \n 6 Brazil      Women    32    19 11-20       \n 7 Bulgaria    Women    19     8 1-10        \n 8 Canada      Women   171    15 11-20       \n 9 Chile       Women    20    10 1-10        \n10 China       Women   291    13 11-20       \n# … with 39 more rows\n\n\n\nexp_women_maplayer_v2 <- world_map %>%\n  right_join(exp_women_v2, by=c(\"geounit\"=\"citizenship\"))\n\nmap_v2 <- ggplot() +\n  geom_sf(data=world_map, size=0.25, color=\"#888888\", fill=\"#f9f9f9\") +\n  geom_sf(data=exp_women_maplayer_v2, size=0.15, color=\"#888888\", alpha=0.7, aes(fill=pct_group)) +\n  scale_fill_manual(values=c(\"#fcbf49\", \"#f77f00\", \"#d62828\")) +\n  theme_void() +\n  theme(plot.title = element_text(face=\"bold\"),\n        plot.title.position = \"plot\",\n        legend.position = \"top\", \n        legend.justification = \"left\",\n        legend.direction = \"horizontal\",\n        legend.text = element_text(margin = margin(r=0.25, unit=\"cm\"), size = 10),\n        text = element_text(family = \"Commissioner\"),\n        panel.background = element_rect(fill = \"#fff7f5\", color = NA),\n        legend.box.margin = margin(c(0,0,0,-2))\n        #legend.spacing.x = unit(0.25, 'cm')\n        ) +\n  labs(fill=NULL,\n       title=\"% of Expeditions Undertaken by Women\",\n       subtitle=\"Includes countries with at least 10 expeditions by women\\n\",\n       caption = \"Source: #TidyTuesday | Himalayan Database\")\n\n# completely fill background with specified page color (eliminating white bands as happened when only running the plot)\n# https://gis.stackexchange.com/questions/269224/ggplot2-map-with-colored-background-and-coord-map\ncowplot::ggdraw(map_v2) + \n  theme(plot.background = element_rect(fill=\"#fff7f5\", color = NA))"
  },
  {
    "objectID": "posts/eurovision/index.html",
    "href": "posts/eurovision/index.html",
    "title": "A Eurovision History",
    "section": "",
    "text": "Final result: See full chart below."
  },
  {
    "objectID": "posts/eurovision/index.html#exploring-the-dataset",
    "href": "posts/eurovision/index.html#exploring-the-dataset",
    "title": "A Eurovision History",
    "section": "Exploring the dataset",
    "text": "Exploring the dataset\n\n\n\n\n\n\nAn American attempts to explain Eurovision\n\n\n\n\n\nEvery year, more than 40 countries across Europe, and from other continents, participate in the Eurovision Song Contest, a continent (and beyond)-wide extravaganza complete with sparkles and Hard Rock Hallelujah. In the case of the dataset, it lists every artist and song performed on the show since the inaugural show in 1956. The competition has been held annually since then, except in 2020.\n\n\n\nA bit of wrangling of this dataset can give some insight into how the history of the competition and how it has changed through the decades to include more countries. Here’s a glimpse of the original dataset:\n\nglimpse(eurovision)\n\nRows: 2,005\nColumns: 18\n$ event          <chr> \"Turin 2022\", \"Turin 2022\", \"Turin 2022\", \"Turin 2022\",…\n$ host_city      <chr> \"Turin\", \"Turin\", \"Turin\", \"Turin\", \"Turin\", \"Turin\", \"…\n$ year           <dbl> 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2…\n$ host_country   <chr> \"Italy\", \"Italy\", \"Italy\", \"Italy\", \"Italy\", \"Italy\", \"…\n$ event_url      <chr> \"https://eurovision.tv/event/turin-2022\", \"https://euro…\n$ section        <chr> \"first-semi-final\", \"first-semi-final\", \"first-semi-fin…\n$ artist         <chr> \"Kalush Orchestra\", \"S10\", \"Amanda Georgiadi Tenfjord\",…\n$ song           <chr> \"Stefania\", \"De Diepte\", \"Die Together\", \"Saudade, Saud…\n$ artist_url     <chr> \"https://eurovision.tv/participant/kalush-orchestra-22\"…\n$ image_url      <chr> \"https://static.eurovision.tv/hb-cgi/images/963164d0-06…\n$ artist_country <chr> \"Ukraine\", \"Netherlands\", \"Greece\", \"Portugal\", \"Bulgar…\n$ country_emoji  <chr> \":flag_ua:\", \":flag_nl:\", \":flag_gr:\", \":flag_pt:\", \":f…\n$ running_order  <dbl> 6, 8, 15, 10, 7, 5, 17, 16, 3, 9, 4, 14, 11, 1, 12, 2, …\n$ total_points   <dbl> 337, 221, 211, 208, 29, 15, 187, 177, 159, 154, 118, 10…\n$ rank           <dbl> 1, 2, 3, 4, 16, 17, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, …\n$ rank_ordinal   <chr> \"1st\", \"2nd\", \"3rd\", \"4th\", \"16th\", \"17th\", \"5th\", \"6th…\n$ qualified      <lgl> TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, TRUE, TRUE, TRUE,…\n$ winner         <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,…\n\n\nTo start off, how many countries have participated each year?\n\n# divide up years on x-axis by decades\ndecade_breaks <- c(1960,1970,1980,1990,2000,2010,2020)\n\neurovision %>%\n  select(year, artist_country) %>%\n  distinct() %>%\n  count(year) %>%\n  ggplot(aes(x=year, y=n)) + \n  geom_col(fill=\"#F7C04A\", color=\"black\", size=0.25, alpha=0.6, width=1, show.legend=FALSE) +\n  scale_x_continuous(limits=c(1955,2023),\n                     breaks=decade_breaks,\n                     expand=c(0, 0)) +\n  scale_y_continuous(expand=c(0, 0), limits=c(0, 45)) +\n  theme_minimal() +\n  theme(plot.title = element_text(family=\"DM Serif Display\", size=rel(1.75)),\n        plot.title.position = \"plot\",\n        legend.position = \"top\", \n        legend.justification = \"left\",\n        legend.direction = \"horizontal\",\n        legend.background = element_rect(fill=\"#fff7f5\", color=NA),\n        legend.text = element_text(margin=margin(r=0.28, unit=\"cm\"), size=10),\n        legend.box.margin = margin(c(0,0,0,-77)),\n        text = element_text(family=\"Trade Gothic LT Std\", color=\"#313131\"),\n        plot.caption = element_textbox_simple(color=\"#666666\"),\n        axis.title = element_text(size=rel(0.75), color=\"#525E75\"),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.y = element_line(size=0.15),\n        panel.grid.major.y = element_line(size=0.2)) +\n  labs(title=\"Eurovision: Number of Participating Countries by Year\",\n       caption=NULL,\n       x=\"Year\",\n       y=\"Number of countries\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\n\n\n\n Note: While the competition was not held in 2020, the list of participants had already been determined. Also, what happened in 1970?1\nEach row of the dataset includes, among other details, the year, song and singer, as well as the stage of the competition in which the performance took place. A look into the data reveals how over the years, the contest has expanded to include more countries, which in turn led to multiple segments of the eshow.\nWhich years had which segments?\n\neurovision %>%\n  # keep only select variables\n  select(host_city, year, host_country, section) %>%\n  distinct() %>%\n  # combine sections (ex. merge \"semi-final\" and \"grand-final\" rows that are in the same year into \"semi-final, grand-final\")\n  group_by(year) %>% \n  mutate(sections = paste0(section, collapse = \", \")) %>%\n  # How many of each type of combination of competition sections?\n  count(sections) %>% \n  ungroup() %>%\n  group_by(sections) %>%\n  # for each section, get the earliest and latest year to get range\n  summarize(first_year = min(year), last_year = max(year)) %>%\n  # sort by earliest year\n  arrange(first_year) %>% \n  select(Sections=sections, `Earliest year`=first_year, `Latest year`=last_year) %>%\n  kable()\n\n\n\n\n\n\n\n\n\nSections\nEarliest year\nLatest year\n\n\n\n\nfinal\n1956\n2003\n\n\nsemi-final, grand-final\n2004\n2007\n\n\nfirst-semi-final, second-semi-final, grand-final\n2008\n2022\n\n\n\n\n\n Results: For nearly 50 years, the competition included only one level, the “final” show. In 2004, following an influx of new participating countries, organizers introduced the semi-final stage, the top 10 of which proceeded to the final – along with the top 10 from the 2003 final, the host country and the five automatically qualifying countries of France, Germany, Italy, Spain and the UK.\nIn 2008, the competition started holding two simultaneous semi-finals with qualifiers from each section (along with 🇫🇷 🇩🇪 🇮🇹 🇪🇸 🇬🇧 and the host country) making up the finalists.2\nAs evident in the dataset, only in 1956 did each of the participating countries (seven at the time) have two performances, either performed by the same or different people, with only two rankings in the end: One entry, representing the host country of Switzerland, (Lys Assia performing Refrain) placed first while the other 13 performances placed “second,” at least in the sense that ranked results beyond the winner were not announced.\n\neurovision %>%\n  filter(year==1956) %>%\n  arrange(rank) %>%\n  select(Artist=artist, Song=song, `Artist's Country`=artist_country, Rank=rank) %>%\n  kable()\n\n\n\n\n\n\n\n\n\n\nArtist\nSong\nArtist’s Country\nRank\n\n\n\n\nLys Assia\nRefrain\nSwitzerland\n1\n\n\nTonina Torielli\nAmami Se Vuoi\nItaly\n2\n\n\nMichèle Arnaud\nLes Amants De Minuit\nLuxembourg\n2\n\n\nDany Dauberson\nIl Est Là\nFrance\n2\n\n\nFreddy Quinn\nSo Geht Das Jede Nacht\nGermany\n2\n\n\nMony Marc\nLe Plus Beau Jour De Ma Vie\nBelgium\n2\n\n\nCorry Brokken\nVoorgoed Voorbij\nNetherlands\n2\n\n\nFranca Raimondi\nAprite Le Finestre\nItaly\n2\n\n\nMichèle Arnaud\nNe Crois Pas\nLuxembourg\n2\n\n\nMathé Altéry\nLe Temps Perdu\nFrance\n2\n\n\nWalter Andreas Schwarz\nIm Wartesaal Zum Großen Glück\nGermany\n2\n\n\nFud Leclerc\nMessieurs Les Noyés De La Seine\nBelgium\n2\n\n\nLys Assia\nDas Alte Karussell\nSwitzerland\n2\n\n\nJetty Paerl\nDe Vogels Van Holland\nNetherlands\n2"
  },
  {
    "objectID": "posts/eurovision/index.html#visualization",
    "href": "posts/eurovision/index.html#visualization",
    "title": "A Eurovision History",
    "section": "Visualization",
    "text": "Visualization\nThe visualization will include only the countries that have made it to at least one final stage of a competition. I have manipulated the data accordingly. Here’s a random sample of the result:\n\neurovision_plot <- eurovision %>%\n  select(year, section, artist_country, rank) %>%\n  distinct() %>%\n  # narrow down to winners and non-winners\n  filter(section==\"final\" | section==\"grand-final\") %>%\n  group_by(year) %>%\n  arrange(rank) %>%\n  # remove non-winners of 1956 as other ranks were not specified\n  filter(!(year==1956 & rank==1)) %>% \n  arrange(-year) %>% # order by most recent\n  # assign placement to make it easier to assign color\n  mutate(rank_text = case_when(\n    rank==1 ~ \"First\",\n    rank==2 ~ \"Second\",\n    rank==3 ~ \"Third\",\n    rank==max(rank)-2 ~ \"Bottom 3\",\n    rank==max(rank)-1 ~ \"Bottom 3\",\n    rank==max(rank) ~ \"Bottom 3\")) %>%\n  ungroup() %>%\n  select(artist_country, year, rank, rank_text) %>% \n  arrange(artist_country)\n\neurovision_plot %>% \n  select(Country=artist_country, Year=year, Rank=rank, `Rank group`=rank_text) %>%\n  sample_n(5) %>%\n  kable()\n\n\n\n\nCountry\nYear\nRank\nRank group\n\n\n\n\nGermany\n1970\n3\nThird\n\n\nCyprus\n2012\n16\nNA\n\n\nNetherlands\n1994\n23\nBottom 3\n\n\nBelgium\n1986\n1\nFirst\n\n\nGreece\n2014\n20\nNA\n\n\n\n\n\n\nAre there any countries that never made it to a final stage?\n\nsetdiff(eurovision$artist_country, eurovision_plot$artist_country) %>%\n  sort() %>% # alphabetize\n  paste0(., collapse = \", \") # transform to single element of countries separated by commas that can be selected and copied into the ggplot code\n\n[1] \"Andorra\"\n\n\nHere is the visualization:\n\nshapes <- c(\"First\"=24, \"Second\"=24, \"Third\"=24, \"Bottom 3\"=25)\n\nrank_colors <- c(\"First\"=\"#FFC600\", \"Second\"=\"#73777B\", \"Third\"=\"#AD7A54\", \"Bottom 3\" = \"#E83A14\")\n\ny_limits <- c(1955,2023)\n\ny_breaks <- seq(1956,2022,2)\n\nplot_theme <- theme(text = element_text(family = \"IBM Plex Sans\", color = \"#383838\"),\n          axis.text.y = element_text(size=rel(0.8)),\n          axis.text.x = element_text(family=\"DM Serif Display\", size=rel(1.25)),\n          plot.title = element_text(family=\"DM Serif Display\", size=rel(1.5), hjust = 0.5),\n          plot.title.position = \"plot\",\n          plot.subtitle = element_textbox_simple(color = \"#383838\", hjust = 0.5, size=rel(0.8)),\n          plot.caption = element_textbox_simple(color = \"#818181\", size=rel(0.7)),\n          # legend\n          legend.position = \"top\", \n          legend.justification = \"left\",\n          legend.direction = \"horizontal\",\n          #legend.box.margin = margin(c(-5,0,-10,-115)),\n          legend.text = element_text(margin = margin(r = 0.4, unit = 'cm'), size=rel(0.7)),\n          legend.title = element_blank(),\n          legend.background = element_blank(),\n          legend.key = element_blank(), # color around symbol in legend\n          # lines for countries\n          panel.grid.major.y = element_line(size = 0.2, color = \"#383838\"),\n          axis.ticks.y = element_line(size = 0.2, color = \"#383838\"),\n          # lines for labeled years\n          panel.grid.major.x = element_line(size = 0.25, color = \"#847e7e\", linetype = 2),\n          panel.grid.minor.x = element_line(size = 0.2, color = \"#b7b2b2\", linetype = 2), #e0dede\n          axis.ticks.x = element_line(size = 0.25, color = \"#847e7e\"),\n          panel.background = element_blank(),\n          plot.background = element_rect(fill = \"transparent\", color = NA)) \n\neurovision_earliest_yr <- eurovision %>%\n  # create df of when country joined\n  select(year, section, artist_country) %>%\n  group_by(artist_country) %>%\n  summarize(earliest_yr = min(year)) %>%\n  # create character vector of just color numbers in same order as unique list of the countries\n  right_join(eurovision_plot)\n\neurovision_earliest_yr %>%\n  mutate(country_year = paste0(\"<strong>\",artist_country,\"</strong> <span style='color:#818181; font-size: 8px;'>\", earliest_yr, \"</span>\")) %>%\n  mutate(country_year = fct_rev(country_year)) %>%\n  ggplot(aes(x=country_year, y=year, fill=rank_text), color=\"white\") +\n  geom_point(aes(shape=rank_text), color=\"transparent\", size=1.5) +\n  scale_shape_manual(values=shapes) +\n  scale_fill_manual(values=rank_colors) +\n  scale_y_continuous(limits=y_limits,\n                     breaks=decade_breaks,\n                     minor_breaks=y_breaks,\n                     expand = c(0, 0),\n                     position=\"right\") +\n  plot_theme +\n  theme(axis.text.y = element_markdown()) +\n  coord_flip() +\n  annotate(\"rect\",\n           ymin = -Inf,\n           ymax = 2003,\n           xmin = -Inf,\n           xmax = Inf,\n           fill = \"#D7E9B9\", alpha = 0.3) +\n  annotate(\"rect\",\n           ymin = 2003,\n           ymax = 2007,\n           xmin = -Inf,\n           xmax = Inf,\n           fill = \"#FFD495\", alpha = 0.3) +\n  annotate(\"rect\",\n           ymin = 2007,\n           ymax = Inf,\n           xmin = -Inf,\n           xmax = Inf,\n           fill = \"#FAAB78\", alpha = 0.3) +\n  labs(title=\"Eurovision: Top and Bottom 3\",\n         subtitle=\"<br />From <span style='color: #5e842c;'>1956 through 2003, the contest only had a final round</span> whereas from <span style='color: #fd9d3a;'>2004 to 2007, the competition introduced an additional semi-final round</span>. Since <span style='color: #e54111;'>2008, Eurovision has had two simultaneous semi-finals</span> in addition to the grand final.\",\n         caption=\"<br />A ranking may include multiple countries. The inaugural competition in 1956 was not included due to only the winner being announced (Switzerland).\",\n         x=NULL, y=NULL)"
  },
  {
    "objectID": "posts/eurovision/index.html#code-for-next-time",
    "href": "posts/eurovision/index.html#code-for-next-time",
    "title": "A Eurovision History",
    "section": "Code for next time",
    "text": "Code for next time"
  },
  {
    "objectID": "posts/international-cities-us/index.html",
    "href": "posts/international-cities-us/index.html",
    "title": "International Place Names Inside the U.S.",
    "section": "",
    "text": "This post describes how I put together the dataset for this map that finds US municipalities that match or include as part of its name a country or international city in English."
  },
  {
    "objectID": "posts/international-cities-us/index.html#gathering-the-data",
    "href": "posts/international-cities-us/index.html#gathering-the-data",
    "title": "International Place Names Inside the U.S.",
    "section": "Gathering the data",
    "text": "Gathering the data\n\nDataset: Names of municipalities in the US\nThe U.S. Board on Geographic Names has available the names of geographic entities in U.S. states, including municipalities, buildings, properties, natural features and more. Data is also available on geographic names across the world.\nFor this exercise, I downloadeded the file PopulatedPlaces_National_Text.zip via the Domestic Names page:\nAfter scanning through the dataset, I’m removing places with (historical) in the name and without a geographic location provided.\n\nus_muni_edit <- us_muni %>%\n  filter(!str_detect(feature_name, regex(\"(historical)\"))) %>%\n  filter(!prim_lat_dec==0) %>%\n  # remove white space\n  mutate(feature_name = str_squish(feature_name))\n\n\n\nDataset: Names of countries and international cities\nThe maps package provides a list of cities via the world.cities dataframe, which includes the country name, population, latitude and longitude coordinates, and whether the city is the capital.\n\nglimpse(maps::world.cities)\n\nRows: 43,645\nColumns: 6\n$ name        <chr> \"'Abasan al-Jadidah\", \"'Abasan al-Kabirah\", \"'Abdul Hakim\"…\n$ country.etc <chr> \"Palestine\", \"Palestine\", \"Pakistan\", \"Kuwait\", \"Palestine…\n$ pop         <int> 5629, 18999, 47788, 21817, 2456, 3434, 9198, 5492, 22706, …\n$ lat         <dbl> 31.31, 31.32, 30.55, 29.36, 32.03, 32.03, 9.77, 2.75, 32.0…\n$ long        <dbl> 34.34, 34.35, 72.11, 47.98, 35.07, 35.20, 44.65, 46.30, 45…\n$ capital     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nTo narrow down the more than 43,500 cities, I’ll filter for only cities with more than 1 million residents, not including metro areas.\nFor each country and international city name, I will add to the end of each name \\\\b, the regular expression to indicate that it’s the end of the word. This way, I will be able to search for US municipalities that contain the name on its own, either by itself or with another word but not as part of a word: This would include “Canada Shores, Michigan” but not “Jordantown, New Jersey.”\n\n\ncities_1m <- maps::world.cities %>%\n  # include only cities with more than 1m people\n  filter(pop > 1000000) %>%\n  # remove US cities\n  filter(country.etc != \"USA\") %>%\n  # add regex to city and country names so that results won't return int'l names within a US city\n  mutate(city_regex = paste0(name, \"\\\\b\")) %>%\n  mutate(country_regex = paste0(country.etc, \"\\\\b\"))\n\n# since I'm taking a random sample of five rows, I will use set.seed() to get the same five rows each time the code is run\nset.seed(10)\nsample_n(cities_1m, 5)\n\n      name  country.etc      pop    lat   long capital  city_regex\n1    Kazan       Russia  1104802  55.75  49.13       0    Kazan\\\\b\n2    Delhi        India 11215130  28.67  77.21       0    Delhi\\\\b\n3 Pretoria South Africa  1687779 -25.73  28.22       1 Pretoria\\\\b\n4   Tehran         Iran  7160094  35.67  51.43       1   Tehran\\\\b\n5     Kobe        Japan  1535384  34.68 135.17       0     Kobe\\\\b\n    country_regex\n1       Russia\\\\b\n2        India\\\\b\n3 South Africa\\\\b\n4         Iran\\\\b\n5        Japan\\\\b"
  },
  {
    "objectID": "posts/international-cities-us/index.html#matching-countries",
    "href": "posts/international-cities-us/index.html#matching-countries",
    "title": "International Place Names Inside the U.S.",
    "section": "Matching countries",
    "text": "Matching countries\nTo “match” US names to country names:\n\nThe column of country names, which will have repeated names, from the cities_1m dataframe (above) will be separated by a vertical bar (|) so that each country name will be searched for among the column of US names and if found, the US names containing a country name will be “extracted” (i.e. kept) in the final list. This will go in the match column.\nAdd a column containing the continent name based on the country names in the match column using the countrycode package. (source)\n\n\ncountry_matches <- us_muni_edit %>%\n  # match US city to country names\n  mutate(match = str_extract(feature_name, paste(cities_1m$country_regex, collapse=\"|\"))) %>%\n  drop_na(match) %>% # remove US names that did not \"match\" any country name\n  # add continent\n  mutate(continent = countrycode::countrycode(sourcevar = match,\n                                              origin = \"country.name\", \n                                              destination = \"continent\"))\n  # narrow down variables\n\nA sample of the final dataframe of US municipalities that now includes the name of a country.\n\nset.seed(123) # set.seed() lets you see the same random sample each time you run the code\nsample_n(country_matches, 10)\n\n   feature_id               feature_name   feature_class    state_name\n1     1379539                China Creek Populated Place         Texas\n2     1554236                       Cuba Populated Place West Virginia\n3      607936                       Peru Populated Place Massachusetts\n4     2481457            Armenia Terrace Populated Place       Florida\n5      669699                      Egypt Populated Place   Mississippi\n6      490449                       Cuba Populated Place      Kentucky\n7     1049099              Poland Center Populated Place          Ohio\n8      867976                    Lebanon Populated Place New Hampshire\n9      942484 Angola Lake Shore Addition Populated Place      New York\n10      57707                      Egypt Populated Place      Arkansas\n   state_numeric  county_name county_numeric         map_name date_created\n1             48     San Saba            411 Blucher Mountain   11/30/1979\n2             54      Jackson             35       Sandyville   06/27/1980\n3             25    Berkshire              3             Peru   02/24/1974\n4             12 Hillsborough             57  Sulphur Springs   07/18/2008\n5             28       Holmes             51       Montgomery   09/24/1980\n6             21       Graves             83             Cuba   09/20/1979\n7             39     Mahoning             99         Campbell   07/12/1979\n8             33      Grafton              9          Hanover   08/27/1980\n9             36         Erie             29          Farnham   01/23/1980\n10             5    Craighead             31             Cash   04/30/1980\n   date_edited bgn_type bgn_authority bgn_date prim_lat_dms prim_long_dms\n1   06/07/2022                                      311533N      0984723W\n2   06/07/2022                                      385928N      0814008W\n3   12/02/2019                                      422617N      0730245W\n4   06/07/2022                                      280005N      0822910W\n5   06/07/2022                                      332028N      0901638W\n6   06/07/2022                                      363506N      0883745W\n7   09/30/2019                                      410126N      0803402W\n8   06/07/2022                                      433832N      0721506W\n9   09/11/2019                                      423705N      0790554W\n10  06/07/2022                                      355205N      0905644W\n   prim_lat_dec prim_long_dec   match continent\n1      31.25906     -98.78977   China      Asia\n2      38.99119     -81.66902    Cuba  Americas\n3      42.43814     -73.04593    Peru  Americas\n4      28.00140     -82.48600 Armenia      Asia\n5      33.34123     -90.27731   Egypt    Africa\n6      36.58506     -88.62922    Cuba  Americas\n7      41.02395     -80.56729  Poland    Europe\n8      43.64229     -72.25176 Lebanon      Asia\n9      42.61811     -79.09837  Angola    Africa\n10     35.86813     -90.94568   Egypt    Africa"
  },
  {
    "objectID": "posts/international-cities-us/index.html#matching-international-cities",
    "href": "posts/international-cities-us/index.html#matching-international-cities",
    "title": "International Place Names Inside the U.S.",
    "section": "Matching international cities",
    "text": "Matching international cities\nFollowing the same steps above, this time matching US municipalities to international city names. And:\n\nJoining this dataframe with the cities_1m in order to include the country for each city.\nAs “Serbia and Montenegro” was given as the country for “Belgrade”, changing the name to “Serbia”.\n\n\ncity_matches <- us_muni_edit %>%\n  # match US city to int'l city names\n  mutate(match = str_extract(feature_name, paste(cities_1m$city_regex, collapse=\"|\"))) %>%\n  drop_na(match) %>%\n  # add country to match (city)\n  left_join(cities_1m, by = c(\"match\" = \"name\")) %>%\n  select(-lat, -long) %>% # removing these cols from cities_1m to avoid confusion\n  # change \"Serbia and Montenegro\" to \"Serbia\"\n  mutate(country.etc = str_replace(country.etc, \"Serbia and Montenegro\", \"Serbia\")) %>%\n  # add continent\n  mutate(continent = countrycode::countrycode(sourcevar = country.etc,\n                                              origin = \"country.name\", \n                                              destination = \"continent\")) %>%\n  # add coordinates for the int'l cities using tidygeocoder pkg\n  mutate(address = paste0(match, \", \", country.etc)) %>%\n  geocode(address, method=\"osm\", lat=city_lat, long=city_long) %>%\n  # narrow down columns\n  select(us_city=feature_name, state_name, us_city_lat=prim_lat_dec, us_city_long=prim_long_dec, intl_city=match, country=country.etc, city_lat, city_long, continent)\n\nA sample of the final dataframe for US towns and cities containing the names of international cities.\n\n# see sample of result\nset.seed(123)\nsample_n(city_matches, 10)\n\n# A tibble: 10 × 9\n   us_city       state…¹ us_ci…² us_ci…³ intl_…⁴ country city_…⁵ city_…⁶ conti…⁷\n   <chr>         <chr>     <dbl>   <dbl> <chr>   <chr>     <dbl>   <dbl> <chr>  \n 1 New London    North …    35.4   -80.2 London  UK         51.5  -0.144 Europe \n 2 Delhi         Ohio       39.1   -84.6 Delhi   India      28.6  77.2   Asia   \n 3 Tripoli       Iowa       42.8   -92.3 Tripoli Libya      32.9  13.2   Africa \n 4 Paris Point   South …    34.9   -82.4 Paris   France     48.9   2.35  Europe \n 5 Hamburg       Kansas     38.1   -99.2 Hamburg Germany    53.6  10.0   Europe \n 6 Brussels      Illino…    38.9   -90.6 Brusse… Belgium    50.9   4.35  Europe \n 7 Melbourne     Missou…    40.1   -93.8 Melbou… Austra…   -37.8 145.    Oceania\n 8 North Belgra… Maine      44.5   -69.8 Belgra… Serbia     44.8  20.5   Europe \n 9 New London    Maryla…    39.4   -77.3 London  UK         51.5  -0.144 Europe \n10 Prague        Arkans…    34.3   -92.3 Prague  Czech …    50.1  14.4   Europe \n# … with abbreviated variable names ¹​state_name, ²​us_city_lat, ³​us_city_long,\n#   ⁴​intl_city, ⁵​city_lat, ⁶​city_long, ⁷​continent"
  },
  {
    "objectID": "posts/international-cities-us/index.html#one-final-thing",
    "href": "posts/international-cities-us/index.html#one-final-thing",
    "title": "International Place Names Inside the U.S.",
    "section": "One Final Thing",
    "text": "One Final Thing\nAfter exporting city_matches via write_csv(city_matches, \"city_matches.csv\"), I used D3.js to create a map that lets users click a major non-US city and see the locations of US towns and cities that share the name. I’ll save country_matches maybe for another time.\nTo end this post, here are the top 10 international cities that appear most frequently as or within US municipality names:\n\ncity_matches %>% count(intl_city, sort=T)\n\n# A tibble: 71 × 2\n   intl_city     n\n   <chr>     <int>\n 1 Berlin       57\n 2 London       49\n 3 Paris        46\n 4 Dublin       38\n 5 Rome         37\n 6 Hamburg      35\n 7 Leon         33\n 8 Cairo        30\n 9 Vienna       29\n10 Damascus     27\n# … with 61 more rows"
  },
  {
    "objectID": "posts/chocolate-bars/index.html",
    "href": "posts/chocolate-bars/index.html",
    "title": "Chocolate Bars",
    "section": "",
    "text": "For the week of January 18, 2022, #TidyTuesday featured the “Chocolate Bar Ratings” dataset from Flavors of Cacao. The reviews span from 2006 through 2022 and for each bar, details include the manufacturer and their location, the chocolate bean origin, ingredients and keyword-descriptions of each bar’s “most memorable characteristics, and of course, the rating.\nAs noted on the website, the chocolate included in the ratings database are a sampling of bars, not a comprehensive assessment of chocolate bars but rather rating dark chocolate bars based on one bar.\n\n\n\n\n\n\nEach chocolate is evaluated from a combination of both objective qualities and subjective interpretation. A rating here only represents an experience with one bar from one batch.  (…)  The database is narrowly focused on plain dark chocolate with an aim of appreciating the flavors of the cacao when made into chocolate.\n\n\n\nLooking at a glimpse of the dataset…\n\nlibrary(tidyverse)\nchocolate_raw <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-18/chocolate.csv')\n\nglimpse(chocolate_raw)\n\nRows: 2,530\nColumns: 10\n$ ref                              <dbl> 2454, 2458, 2454, 2542, 2546, 2546, 2…\n$ company_manufacturer             <chr> \"5150\", \"5150\", \"5150\", \"5150\", \"5150…\n$ company_location                 <chr> \"U.S.A.\", \"U.S.A.\", \"U.S.A.\", \"U.S.A.…\n$ review_date                      <dbl> 2019, 2019, 2019, 2021, 2021, 2021, 2…\n$ country_of_bean_origin           <chr> \"Tanzania\", \"Dominican Republic\", \"Ma…\n$ specific_bean_origin_or_bar_name <chr> \"Kokoa Kamili, batch 1\", \"Zorzal, bat…\n$ cocoa_percent                    <chr> \"76%\", \"76%\", \"76%\", \"68%\", \"72%\", \"8…\n$ ingredients                      <chr> \"3- B,S,C\", \"3- B,S,C\", \"3- B,S,C\", \"…\n$ most_memorable_characteristics   <chr> \"rich cocoa, fatty, bready\", \"cocoa, …\n$ rating                           <dbl> 3.25, 3.50, 3.75, 3.00, 3.00, 3.25, 3…\n\n\n…here are some initial observations about the variables:\n\n\n\n\n\n\n\n\n\nVariable\nDetails\n\n\n\n\nManufacturer\n580 companies\n\n\nCompany location\n67 countries\n\n\nYear of review\n2006-2021\n\n\nCountry where bean originated\n62 countries\n\n\nCocoa %\nseeds (or beans) that produce chocolate\n\n\nIngredients\nB = beans, S = sugar, S* = sweetener (not white cane or beet sugar), C = cocoa butter, V = vanilla, L = lecithin, Sa = salt\n\n\nMost memorable characteristics\nkeywords\n\n\nRating\n1-4"
  },
  {
    "objectID": "posts/chocolate-bars/index.html#world-map",
    "href": "posts/chocolate-bars/index.html#world-map",
    "title": "Chocolate Bars",
    "section": "World Map",
    "text": "World Map\nAfter exploring the data, I went with mapping the countries in the dataset, color coding them by whether they:\n\nonly appear as the location of a manufacturing company\nonly appear as a bean origin country\nor both\n\n\n# Are there countries that appear in both columns? (33) Use #C0EDA6\ncountries_both <- chocolate_raw %>%\n  select(company_location, country_of_bean_origin) %>%\n  unique() %>%\n  # isolate countries in company_location that also appear in country_of_bean_origin\n  filter(company_location %in% unique(country_of_bean_origin)) %>%\n  # isolate only company_location and rename\n  select(country=company_location) %>%\n  unique() %>%\n  # add column that gives it green color to signify it appears in both vars\n  add_column(country_type=\"both\")\n\n# countries that appear only in company_location (34) Use #8FBDD3\ncountries_manufacturer <- chocolate_raw %>%\n  select(company_location, country_of_bean_origin) %>%\n  unique() %>%\n  filter(!company_location %in% unique(country_of_bean_origin)) %>%\n  select(country=company_location) %>%\n  unique() %>%\n  add_column(country_type=\"manufacturer\")\n\n# countries that appear only in country_of_bean_origin (29) Use #FFF7BC\nbean_countries <- chocolate_raw %>%\n  select(company_location, country_of_bean_origin) %>%\n  unique() %>%\n  filter(!country_of_bean_origin %in% unique(company_location)) %>%\n  select(country=country_of_bean_origin) %>%\n  unique() %>%\n  add_column(country_type=\"bean origin\")\n\n# combine above three into one df\nchocolate_map <- rbind(countries_both, countries_manufacturer, bean_countries)\n\n\n1. Load world map via rnaturalearth\n\nlibrary(rnaturalearth)\nworld_map <- ne_countries(scale=\"medium\",\n                          type=\"map_units\", # to include Mauritania\n                          returnclass=\"sf\")\n\nggplot() +\n  geom_sf(data=world_map, size=0.25, fill=\"#eeeeee\") +\n  theme_void()\n\n\n\n\n\n\n\n2. Data cleaning\n\nCheck if any country names in world_map and chocolate_map do not match, i.e. Which country names in world_map do not appear in chocolate_map due to spelling differences or more granular divisions within what world_map considers a country. Goal: Create a layer of just the countries in chocolate_map to “layer” on top of the world_map basemap.\n\n\nchocolate_map %>% filter(!country %in% unique(world_map$geounit))\n\n# A tibble: 18 × 2\n   country               country_type\n   <chr>                 <chr>       \n 1 U.S.A.                both        \n 2 Sao Tome              both        \n 3 St. Lucia             both        \n 4 Sao Tome & Principe   both        \n 5 St.Vincent-Grenadines both        \n 6 U.K.                  manufacturer\n 7 Belgium               manufacturer\n 8 Amsterdam             manufacturer\n 9 U.A.E.                manufacturer\n10 Burma                 bean origin \n11 Trinidad              bean origin \n12 Blend                 bean origin \n13 Congo                 bean origin \n14 Tobago                bean origin \n15 Sumatra               bean origin \n16 Principe              bean origin \n17 Sulawesi              bean origin \n18 DR Congo              bean origin \n\n\n\n\nRenaming countries in chocolate_map to how they appear in world_map.\n\n\nchocolate_map_edit <- chocolate_map %>%\n  # rename countries\n  mutate(country = str_replace_all(\n    country,\n    c(\n      \"U.S.A.\" = \"United States of America\", # old = new\n      \"Sao Tome$\" = \"Sao Tome and Principe\",\n      \"St. Lucia\" = \"Saint Lucia\",\n      \"Sao Tome & Principe\" = \"Sao Tome and Principe\",\n      \"St.Vincent-Grenadines\" = \"Saint Vincent and the Grenadines\",\n      \"U.A.E.\" = \"United Arab Emirates\",\n      \"Burma\" = \"Myanmar\",\n      \"^Trinidad$\" = \"Trinidad and Tobago\",\n      \"^Congo$\" = \"Republic of Congo\",\n      \"^Tobago$\" = \"Trinidad and Tobago\",\n      \"^Principe$\" = \"Sao Tome and Principe\",\n      \"DR Congo\" = \"Democratic Republic of the Congo\"\n    )\n  )) %>%\n  # renaming \"non-countries\" as the country in which they're located\n  mutate(country = str_replace_all(\n    country,\n    c(\n      \"Amsterdam\" = \"Netherlands\",\n      \"Sumatra\" = \"Indonesia\",\n      \"Sulawesi\" = \"Indonesia\"\n    )\n  )) %>%\n  # remove country of \"Blend\" and also \"Scotland\" and \"Wales\" as the latter two will be represented by \"United Kingdom\" (all three are only manufacturing countries, plus \"England\" and \"Northern Ireland\" were not included in the chocolate data)\n  filter(!country %in% c(\"Blend\", \"Scotland\", \"Wales\")) %>%\n  # renamings will produce duplicates so remove those\n  unique()\n\n\n\nCheck: Rerun code from a to see if any countries from chocolate_map remain off of world_map.\n\n\nchocolate_map %>% filter(!country %in% unique(world_map$geounit))\n\n# A tibble: 18 × 2\n   country               country_type\n   <chr>                 <chr>       \n 1 U.S.A.                both        \n 2 Sao Tome              both        \n 3 St. Lucia             both        \n 4 Sao Tome & Principe   both        \n 5 St.Vincent-Grenadines both        \n 6 U.K.                  manufacturer\n 7 Belgium               manufacturer\n 8 Amsterdam             manufacturer\n 9 U.A.E.                manufacturer\n10 Burma                 bean origin \n11 Trinidad              bean origin \n12 Blend                 bean origin \n13 Congo                 bean origin \n14 Tobago                bean origin \n15 Sumatra               bean origin \n16 Principe              bean origin \n17 Sulawesi              bean origin \n18 DR Congo              bean origin \n\n\n\n\nRemove\n\n\nchocolate_map_edit <- chocolate_map_edit %>% filter(!country %in% c(\"U.K.\", \"Belgium\"))\n\n\n\nWorkaround: Add a third layer for Belgium and the UK since their geounit in world_map was of regions within those countries so using the admin column here in place of geounit as used above.\n\n\nchocolate_map <- chocolate_map %>%\n  mutate(country = str_replace(country, \"U.K.\", \"United Kingdom\"))\n\nbel_uk_layer <- world_map %>%\n  filter(admin %in% c(\"Belgium\", \"United Kingdom\")) %>%\n  left_join(chocolate_map, by=c(\"admin\"=\"country\"))\n\n\n\nright_join() the world_map and chocolate_map_edit dataframes in order to add geographic components to chocolate_map_edit.\n\n\ncombo_map <- world_map %>% right_join(chocolate_map_edit, by=c(\"geounit\"=\"country\"))\n\n\n\n3. Chocolate map\nAdding the three layers: (1) world_map: Base world map + (2) combo_map: Countries from the chocolate data + (3) bel_uk_layer: Belgium and the UK\n\nggplot() +\n  geom_sf(data=world_map, size=0.25, fill=\"#eeeeee\") +\n  geom_sf(data=combo_map, aes(fill=country_type), size=0.25, show.legend=F) +\n  geom_sf(data=bel_uk_layer, aes(fill=country_type), size=0.25, show.legend=F) +\n  scale_fill_manual(values = c(\"both\" = \"#C0EDA6\", # df value = color\n                               \"manufacturer\" = \"#8FBDD3\",\n                               \"bean origin\" = \"#FFF7BC\")) +\n  theme_void()"
  },
  {
    "objectID": "posts/chocolate-bars/index.html#out-of-curiosity",
    "href": "posts/chocolate-bars/index.html#out-of-curiosity",
    "title": "Chocolate Bars",
    "section": "Out of Curiosity",
    "text": "Out of Curiosity\nAre there words disproportionately associated with a country where a bean originated or a a country of the manufacturing company?\n\nlibrary(tidytext)\n\nchocolate_raw %>%\n  unnest_tokens(word, most_memorable_characteristics) %>%\n  count(country_of_bean_origin, word, sort = TRUE) %>%\n  bind_tf_idf(term = word, document = country_of_bean_origin, n) %>% # calculates TF-IDF\n  arrange(desc(tf_idf)) %>%\n  #top_n(20, wt = tf_idf) %>%\n  filter(n>20)\n\n# A tibble: 36 × 6\n   country_of_bean_origin word       n     tf   idf tf_idf\n   <chr>                  <chr>  <int>  <dbl> <dbl>  <dbl>\n 1 Papua New Guinea       smoke     27 0.155  1.13  0.176 \n 2 Ecuador                floral    82 0.112  0.795 0.0893\n 3 Madagascar             red       25 0.0394 1.82  0.0719\n 4 Madagascar             sour      44 0.0694 0.631 0.0438\n 5 Venezuela              nutty     88 0.102  0.389 0.0397\n 6 Madagascar             tart      23 0.0363 1.08  0.0393\n 7 Blend                  bitter    24 0.0440 0.795 0.0350\n 8 Ecuador                bitter    30 0.0411 0.795 0.0327\n 9 Blend                  sweet     31 0.0569 0.490 0.0278\n10 Madagascar             fruit     36 0.0568 0.490 0.0278\n# … with 26 more rows\n\nchocolate_raw %>%\n  unnest_tokens(word, most_memorable_characteristics) %>%\n  #count(word, country_of_bean_origin, sort = TRUE) %>%\n  count(word, company_location, sort = TRUE) %>%\n  filter(word == \"smoke\")\n\n# A tibble: 14 × 3\n   word  company_location     n\n   <chr> <chr>            <int>\n 1 smoke U.S.A.              26\n 2 smoke France              10\n 3 smoke Canada               5\n 4 smoke Italy                4\n 5 smoke New Zealand          4\n 6 smoke Australia            3\n 7 smoke U.K.                 3\n 8 smoke Austria              2\n 9 smoke Colombia             2\n10 smoke Japan                2\n11 smoke Ecuador              1\n12 smoke Germany              1\n13 smoke U.A.E.               1\n14 smoke Venezuela            1\n\n# instead of going by word units, break up by placement of comma => there will be one word, two words, etc.\nchocolate_raw %>%\n  select(most_memorable_characteristics, rating) %>%\n  # split at comma\n  separate_rows(most_memorable_characteristics, sep = ',', convert = TRUE) %>%\n  #filter(str_detect(most_memorable_characteristics, regex(\" \"))) %>%\n  group_by(most_memorable_characteristics) %>%\n  summarize(characteristic_count = n(), mean_rating = median(rating)) %>%\n  filter(characteristic_count>20) %>% arrange(desc(mean_rating))\n\n# A tibble: 71 × 3\n   most_memorable_characteristics characteristic_count mean_rating\n   <chr>                                         <int>       <dbl>\n 1 \" banana\"                                        33         3.5\n 2 \" cherry\"                                        27         3.5\n 3 \" citrus\"                                        21         3.5\n 4 \" cocoa\"                                        210         3.5\n 5 \" creamy\"                                        26         3.5\n 6 \" dairy\"                                         34         3.5\n 7 \" dried fruit\"                                   46         3.5\n 8 \" fruity\"                                        37         3.5\n 9 \" honey\"                                         26         3.5\n10 \" melon\"                                         22         3.5\n# … with 61 more rows\n\nchocolate_raw %>%\n  separate_rows(most_memorable_characteristics, sep = ',', convert = TRUE) %>%\n  mutate(most_memorable_characteristics = str_squish(most_memorable_characteristics)) %>%\n  count(country_of_bean_origin, most_memorable_characteristics, sort = TRUE) %>%\n  bind_tf_idf(term = most_memorable_characteristics, document = country_of_bean_origin, n) %>%\n  arrange(desc(tf_idf)) %>%\n  filter(n>20)\n\n# A tibble: 21 × 6\n   country_of_bean_origin most_memorable_characteris…¹     n     tf   idf tf_idf\n   <chr>                  <chr>                        <int>  <dbl> <dbl>  <dbl>\n 1 Ecuador                floral                          72 0.12   0.831 0.0998\n 2 Venezuela              nutty                           84 0.116  0.414 0.0481\n 3 Madagascar             sour                            27 0.0557 0.795 0.0443\n 4 Blend                  sweet                           27 0.0609 0.490 0.0298\n 5 Venezuela              creamy                          33 0.0457 0.601 0.0275\n 6 Blend                  cocoa                           26 0.0587 0.438 0.0257\n 7 Dominican Republic     earthy                          35 0.0546 0.464 0.0253\n 8 Ecuador                spicy                           21 0.035  0.693 0.0243\n 9 Venezuela              roasty                          33 0.0457 0.516 0.0236\n10 Dominican Republic     spicy                           21 0.0328 0.693 0.0227\n# … with 11 more rows, and abbreviated variable name\n#   ¹​most_memorable_characteristics"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Exploring datasets from the Tidy Tuesday community project and other sources, and putting together coding reference sheets\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nA Eurovision History\n\n\n\n\n\n\n\nTidy Tuesday\n\n\nR\n\n\n\n\nA look into the dataset reveals how the song competition has changed in the more than 65-year duration.\n\n\n\n\n\n\nJun 1, 2022\n\n\n\n\n\n\n  \n\n\n\n\nChocolate Bars\n\n\n\n\n\n\n\nTidy Tuesday\n\n\nR\n\n\nmap\n\n\n\n\nA color-coded world map made from a set of chocolate bar ratings.\n\n\n\n\n\n\nMar 28, 2022\n\n\n\n\n\n\n  \n\n\n\n\nInternational Place Names Inside the U.S.\n\n\n\n\n\n\n\nmap\n\n\nR\n\n\n\n\nIdentifying US municipalities that are a name, or part of their name, with that of a country or international city.\n\n\n\n\n\n\nJul 27, 2021\n\n\n\n\n\n\n  \n\n\n\n\nHimalayan Expeditions\n\n\n\n\n\n\n\nTidy Tuesday\n\n\nR\n\n\n\n\nVisualizing a #TidyTuesday-featured dataset on Himalayan expeditions, with a focus on climber nationalities.\n\n\n\n\n\n\nOct 20, 2020\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/international-cities-us/index.html#a-final-list",
    "href": "posts/international-cities-us/index.html#a-final-list",
    "title": "International Place Names Inside the U.S.",
    "section": "A Final List",
    "text": "A Final List\nAfter exporting city_matches via write_csv(city_matches, \"city_matches.csv\"), I used D3.js to create a map that lets users click a major non-US city and see the locations of US towns and cities that share the name. I’ll save country_matches maybe for another time.\nTo end this post, here are the top 10 international cities that appear most frequently as or within US municipality names:\n\ncity_matches %>% count(intl_city, sort=T)\n\n# A tibble: 71 × 2\n   intl_city     n\n   <chr>     <int>\n 1 Berlin       57\n 2 London       49\n 3 Paris        46\n 4 Dublin       38\n 5 Rome         37\n 6 Hamburg      35\n 7 Leon         33\n 8 Cairo        30\n 9 Vienna       29\n10 Damascus     27\n# … with 61 more rows"
  }
]